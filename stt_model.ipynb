{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (0.28.1)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from openai) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.20->openai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.20->openai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.20->openai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.20->openai) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->openai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from aiohttp->openai) (1.9.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-0.4.7-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from langgraph) (0.2.4)\n",
      "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.2.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pydantic>=2.7.4 (from langgraph)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core>=0.1->langgraph) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.66 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core>=0.1->langgraph) (0.1.75)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core>=0.1->langgraph) (23.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core>=0.1->langgraph) (8.3.0)\n",
      "Collecting langchain-core>=0.1 (from langgraph)\n",
      "  Downloading langchain_core-0.3.62-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
      "  Downloading ormsgpack-1.10.0-cp312-cp312-win_amd64.whl.metadata (44 kB)\n",
      "Collecting langsmith<0.4,>=0.1.126 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading langsmith-0.3.42-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core>=0.1->langgraph) (4.10.0)\n",
      "Collecting httpx>=0.25.2 (from langgraph-sdk>=0.1.42->langgraph)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic>=2.7.4->langgraph)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic>=2.7.4->langgraph)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting anyio (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (3.6)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (2.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph)\n",
      "  Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core>=0.1->langgraph) (2.2.1)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langgraph-0.4.7-py3-none-any.whl (154 kB)\n",
      "Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
      "Downloading langchain_core-0.3.62-py3-none-any.whl (438 kB)\n",
      "Downloading langgraph_prebuilt-0.2.1-py3-none-any.whl (23 kB)\n",
      "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 26.9 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading langsmith-0.3.42-py3-none-any.whl (360 kB)\n",
      "Downloading ormsgpack-1.10.0-cp312-cp312-win_amd64.whl (121 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading zstandard-0.23.0-cp312-cp312-win_amd64.whl (495 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, xxhash, typing-extensions, sniffio, ormsgpack, h11, typing-inspection, pydantic-core, httpcore, anyio, pydantic, httpx, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "  Attempting uninstall: xxhash\n",
      "    Found existing installation: xxhash 3.4.1\n",
      "    Uninstalling xxhash-3.4.1:\n",
      "      Successfully uninstalled xxhash-3.4.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.10.0\n",
      "    Uninstalling typing_extensions-4.10.0:\n",
      "      Successfully uninstalled typing_extensions-4.10.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.18.4\n",
      "    Uninstalling pydantic_core-2.18.4:\n",
      "      Successfully uninstalled pydantic_core-2.18.4\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.7.3\n",
      "    Uninstalling pydantic-2.7.3:\n",
      "      Successfully uninstalled pydantic-2.7.3\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.75\n",
      "    Uninstalling langsmith-0.1.75:\n",
      "      Successfully uninstalled langsmith-0.1.75\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.4\n",
      "    Uninstalling langchain-core-0.2.4:\n",
      "      Successfully uninstalled langchain-core-0.2.4\n",
      "Successfully installed anyio-4.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 langchain-core-0.3.62 langgraph-0.4.7 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.2.1 langgraph-sdk-0.1.70 langsmith-0.3.42 ormsgpack-1.10.0 pydantic-2.11.5 pydantic-core-2.33.2 sniffio-1.3.1 typing-extensions-4.13.2 typing-inspection-0.4.1 xxhash-3.5.0 zstandard-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.2.3 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.3.62 which is incompatible.\n",
      "langchain 0.2.3 requires langsmith<0.2.0,>=0.1.17, but you have langsmith 0.3.42 which is incompatible.\n",
      "langchain-community 0.2.4 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.3.62 which is incompatible.\n",
      "langchain-community 0.2.4 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.3.42 which is incompatible.\n",
      "langchain-google-genai 1.0.6 requires langchain-core<0.3,>=0.2.2, but you have langchain-core 0.3.62 which is incompatible.\n",
      "langchain-text-splitters 0.2.1 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.3.62 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in c:\\users\\alice\\appdata\\roaming\\python\\python312\\site-packages (24.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 20.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n",
      "Successfully installed pip-25.1.1\n"
     ]
    }
   ],
   "source": [
    "!python.exe -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"OPEN_AI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_path = \"Record1.mp3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file_path):\n",
    "    with open(file_path, \"rb\") as audio_file:\n",
    "        transcript = openai.Audio.transcribe(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file,\n",
    "            response_format=\"text\"  \n",
    "        )\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription saved to call_transcript.txt\n"
     ]
    }
   ],
   "source": [
    "def save_transcript_to_file(transcript, output_path):\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(transcript)\n",
    "    print(f\"Transcription saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = transcribe_audio(audio_file_path)\n",
    "        save_transcript_to_file(result, \"call_transcript.txt\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **DAG Agnetic AI Workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import openai\n",
    "import os\n",
    "from typing import Annotated, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Define Schema using TypedDict ===\n",
    "class State(TypedDict):\n",
    "    audio_path: str\n",
    "    transcript: str\n",
    "    clean_text: str\n",
    "    summary: str\n",
    "    sentiment: str\n",
    "    note: str\n",
    "    evaluation: str\n",
    "\n",
    "# === 1. STT Agent ===\n",
    "def stt_agent(state) -> Annotated[dict, \"transcript\"]:\n",
    "    audio_path = state[\"audio_path\"]\n",
    "    with open(audio_path, \"rb\") as audio_file:\n",
    "        transcript = openai.Audio.transcribe(\n",
    "            model=\"whisper-1\",\n",
    "            file=audio_file,\n",
    "            response_format=\"text\"\n",
    "        )\n",
    "    return {\"transcript\": transcript}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. Preprocessing Agent ===\n",
    "def preprocess_agent(state) -> Annotated[dict, \"clean_text\"]:\n",
    "    transcript = state[\"transcript\"]\n",
    "    clean = transcript.replace(\"um\", \"\").replace(\"uh\", \"\").replace(\"you know\", \"\")\n",
    "    clean = \" \".join(clean.split())\n",
    "    return {\"clean_text\": clean}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3. Combined Summary and Sentiment Agent ===\n",
    "def summary_sentiment_agent(state) -> Annotated[dict, \"summary | sentiment\"]:\n",
    "    clean_text = state[\"clean_text\"]\n",
    "\n",
    "    prompt_summary = f\"Please summarize the following customer conversation:\\n{clean_text}\"\n",
    "    summary = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_summary}]\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    prompt_sentiment = f\"Analyze the sentiment of the following conversation (positive/negative/neutral):\\n{clean_text}\"\n",
    "    sentiment = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt_sentiment}]\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    return {\"summary\": summary, \"sentiment\": sentiment}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4. Note Writer Agent ===\n",
    "def note_writer_agent(state) -> Annotated[dict, \"note\"]:\n",
    "    summary = state[\"summary\"]\n",
    "    sentiment = state[\"sentiment\"]\n",
    "    prompt = f\"Summary: {summary}\\nSentiment: {sentiment}\\nPlease generate a customer service note based on the above.\"\n",
    "    note = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return {\"note\": note}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5. Evaluation Agent ===\n",
    "def evaluation_agent(state) -> Annotated[dict, \"evaluation\"]:\n",
    "    prompt = f\"\"\"Evaluate the accuracy of the following summary:\n",
    "    Original Text:\\n{state['clean_text']}\n",
    "    Summary:\\n{state['summary']}\n",
    "    Rate it from 1 to 5 and explain your reasoning.\"\"\"\n",
    "    evaluation = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return {\"evaluation\": evaluation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x16c8f74bad0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 6. Construct LangGraph DAG ===\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"STT\", RunnableLambda(stt_agent))\n",
    "builder.add_node(\"Preprocess\", RunnableLambda(preprocess_agent))\n",
    "builder.add_node(\"SummarySentiment\", RunnableLambda(summary_sentiment_agent))\n",
    "builder.add_node(\"NoteWriter\", RunnableLambda(note_writer_agent))\n",
    "builder.add_node(\"Evaluation\", RunnableLambda(evaluation_agent))\n",
    "\n",
    "builder.set_entry_point(\"STT\")\n",
    "builder.add_edge(\"STT\", \"Preprocess\")\n",
    "builder.add_edge(\"Preprocess\", \"SummarySentiment\")\n",
    "builder.add_edge(\"SummarySentiment\", \"NoteWriter\")\n",
    "builder.add_edge(\"NoteWriter\", \"Evaluation\")\n",
    "builder.set_finish_point(\"Evaluation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Note:\n",
      " Subject: Customer Service Training - Key Phrases for Professional Interactions\n",
      "\n",
      "Dear Team,\n",
      "\n",
      "As part of our ongoing commitment to excellent customer service, we are introducing a new training lesson that outlines 36 essential English phrases to enhance your interactions with customers. This training will be particularly beneficial for those of you working in call centers or handling customer calls regularly.\n",
      "\n",
      "The lesson covers a variety of scenarios, including:\n",
      "\n",
      "1. **Greeting Customers:** Learn how to introduce yourself and the company professionally to set a positive tone at the start of each call.\n",
      "\n",
      "2. **Handling Complaints:** Gain key phrases that help you express empathy, apologize sincerely, and reassure customers that assistance is on the way.\n",
      "\n",
      "3. **Transferring Calls:** Use polite and clear communication to inform customers when transfers are necessary, while ensuring they are comfortable with the process.\n",
      "\n",
      "4. **Gathering Information:** Understand the importance of efficiently collecting the relevant customer information when dealing with their concerns directly.\n",
      "\n",
      "Our goal with this training is to provide you with the tools necessary to maintain a professional and courteous tone in all customer interactions, while effectively addressing their needs.\n",
      "\n",
      "Please feel free to reach out if you have any questions or need further clarification on the training. We are here to support you in providing the best customer service possible.\n",
      "\n",
      "Best Regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "[Company Name]\n",
      "\n",
      "Evaluation:\n",
      " I would rate this summary a 4 out of 5.\n",
      "\n",
      "Here's why:\n",
      "1. **Coverage**: The summary captures the main points of the original text effectively, mentioning the introduction of 36 useful phrases for customer service, focusing on call centers, and covering scenarios such as greeting customers, handling complaints, and transferring calls. \n",
      "\n",
      "2. **Clarity**: It clearly explains the purpose of the lesson, the scenarios covered, and the key phrases for professional interaction, making it easy for someone to understand what the lesson entails.\n",
      "\n",
      "3. **Detail**: While the summary conveys the primary elements of the original text, it simplifies and condenses some of the detailed examples provided, which is typical for a summary, but a few specific examples could add more depth to the understanding of certain phrases.\n",
      "\n",
      "4. **Accuracy**: The summary accurately reflects the content of the original text, but it omits the specific structure of the greeting examples and the empathy-related responses, which, while not critical, could add to the completeness of the summary.\n",
      "\n",
      "5. **Conciseness**: The summary is concise and to the point, capturing most essential details without unnecessary information.\n",
      "\n",
      "Overall, the summary performs well in encapsulating the essence of the original text but could improve by adding a few more specific details or examples for enhanced clarity and completeness.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 7. Execute Graph ===\n",
    "graph = builder.compile()\n",
    "\n",
    "initial_state = {\"audio_path\": \"Short_Record1.mp3\"}  \n",
    "output = graph.invoke(initial_state)\n",
    "\n",
    "# === 9. Output Results ===\n",
    "print(\"\\nFinal Note:\\n\", output[\"note\"])\n",
    "print(\"\\nEvaluation:\\n\", output[\"evaluation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the conversation is neutral. The text is an instructional piece, providing guidance on how to handle customer service calls. It does not express any personal emotions or opinions, but rather, it outlines professional customer service phrases and procedures for dealing with calls, including both routine answers and handling complaints. The tone is informative and professional, with the aim of educating, rather than conveying positive or negative feelings.\n"
     ]
    }
   ],
   "source": [
    "print(output['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this customer service training lesson, 36 useful English phrases for professional customer interactions are introduced, particularly beneficial for those working in call centers or handling customer calls. The lesson covers various scenarios, including greeting customers, handling complaints, and transferring calls. Key phrases for answering calls professionally include introducing oneself and the company, and inquiring about how to assist the caller. When dealing with complaints, it's important to express empathy, apologize, and assure the customer of assistance. Additionally, if the caller needs to be transferred, polite phrases for doing so are provided, ensuring the customer is informed and agrees to the process. The lesson also emphasizes the importance of gathering necessary customer information when the service representative is equipped to handle the concern.\n"
     ]
    }
   ],
   "source": [
    "print(output['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I would rate this summary a 4 out of 5.\\n\\nHere's why:\\n1. **Coverage**: The summary captures the main points of the original text effectively, mentioning the introduction of 36 useful phrases for customer service, focusing on call centers, and covering scenarios such as greeting customers, handling complaints, and transferring calls. \\n\\n2. **Clarity**: It clearly explains the purpose of the lesson, the scenarios covered, and the key phrases for professional interaction, making it easy for someone to understand what the lesson entails.\\n\\n3. **Detail**: While the summary conveys the primary elements of the original text, it simplifies and condenses some of the detailed examples provided, which is typical for a summary, but a few specific examples could add more depth to the understanding of certain phrases.\\n\\n4. **Accuracy**: The summary accurately reflects the content of the original text, but it omits the specific structure of the greeting examples and the empathy-related responses, which, while not critical, could add to the completeness of the summary.\\n\\n5. **Conciseness**: The summary is concise and to the point, capturing most essential details without unnecessary information.\\n\\nOverall, the summary performs well in encapsulating the essence of the original text but could improve by adding a few more specific details or examples for enhanced clarity and completeness.\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output['evaluation'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
